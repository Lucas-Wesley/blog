---
title: "IA: Agentes de IA e suas Ferramentas. (Parte 2)"
date: "2025-05-09 22:40"
status: "published"
description: "Agentes de IA e suas ferramentas."
autor: "Lucas Wesley Moreira Tinta"
category: "IA"
slug: "tudo-sobre-agentes-de-ia-e-suas-ferramentas"
tags: ["IA", "Agentes de IA", "Ferramentas de IA", "Agentes"]
---

Acredite, eu resumi muito esse conteúdo. Cada item que mencionei daria para fazer um artigo inteiro se aprofundando. Mas o objetivo aqui é dar uma visão geral do conceito de Agente e como ele pode ser aplicado. 

O disclaimer de sempre: Todas as informações foram retiradas das fontes citadas no final do artigo. 

Já falei sobre LLMs e RAGs, recomendo que leia caso esses termos não sejam familiares para você. Vamos dar mais um passo e entender o que são os Agentes de IA.

[Artigo: Diferença entre LLM, UNET e RAG. - (Parte 1)](1.ia-diferenca-llm-unet-rag)

## Definindo Agente de IA

Antes de tudo, Agente de IA é um **_conceito_**. Não é um produto, não é uma tecnologia, não é um algoritmo. É um conceito que pode ser aplicado de diversas formas.

Uma definição formal de Agente de IA é: Um Agente de IA são sistemas que utilizam inteligência artificial para realizar tarefas de forma autônoma, interagindo com o ambiente ao seu redor.

Essa definição é legal, mas gera algumas dúvidas. **_Que inteligência eles usam? Que tarefas são essas? Quais ambientes?_**
Vamos responder essas perguntas neste artigo.

Esse conceito de Agentes está sendo utilizado sem muito rigor. Qualquer tipo de ferramenta que utiliza IA para automatizar tarefas está sendo chamada de Agente.  

Um Agente é caracterizado por sua autonomia, adaptabilidade e capacidade de aprendizado. Mas o que várias pessoas chamam de Agente, na verdade, são LLMs com mais autonomia. Mas a ideia do Agente é ir além disso: é ter um sistema que aprende e se adapta ao ambiente.

## Tipos de Agentes e o Ciclo de Vida

O primeiro tipo de Agente são os Reativos, que são os mais comuns de ver por aí. Geralmente, eles respondem diretamente a inputs do usuário. Imagine um Agente de código. Ele vai receber uma instrução do usuário, vai gerar o código e os arquivos. Ele não estava monitorando o ambiente, nada. Só estava esperando o input do usuário.

Na maioria dos casos, esses Agentes reativos não possuem memória, ou melhor, não possuem "estado". Não quer dizer que ele não vai executar ações em sequência, mas, uma vez encerrado o ciclo, não vai lembrar dessas informações nas próximas interações.	

Temos também os Agentes "Deliberativos". Esses Agentes "pensam" melhor como executar as tarefas, ou seja, eles vão considerar as possibilidades antes de sair executando.

Tem os Hybrid Agents, que são uma combinação dos dois. Eles podem ser reativos e deliberativos ao mesmo tempo. Ou seja, eles podem ter um ciclo de execução mais longo, mas também podem responder a inputs do usuário.

Vamos ter os Learning Agents, que são Agentes que aprendem com o ambiente, aprendem com sua experiência. 

Na prática, esses Agentes se misturam uns com os outros. 

Mas em "alto nível", o ciclo de vida de um Agente é:
1. **Percepção:** O Agente percebe o ambiente ao seu redor, coletando informações através de eventos ou dados de entrada.
2. **Decisão:** O Agente processa as informações coletadas, analisando e interpretando os dados para tomar decisões informadas.
3. **Ação:** O Agente executa ações com base nas decisões tomadas, interagindo com o ambiente de forma autônoma.
4. **Aprendizado:** O Agente aprende com suas experiências, ajustando seu comportamento e melhorando sua capacidade de tomar decisões ao longo do tempo.
5. **Repetição:** O ciclo se repete, permitindo que o Agente se adapte continuamente ao ambiente e melhore seu desempenho ao longo do tempo.

Nem todos os Agentes conseguem fazer os passos 4 e 5.

Dito isso, vamos para as perguntas que eu fiz no começo. Que inteligência eles usam? Que tarefas são essas? Quais ambientes? 

## Que inteligência elas usam?

A primeira pergunta é fácil de responder. Os agentes vão utilizar LLMs de mercado, como o GPTs, Claude, Gemini, ou quaisquer outros modelos de IA.

Como eu expliquei no artigo anterior sobre LLMs, esses modelos são treinados com dados. E dependendo da maneira que você treina e os tipos de dados, eles vão ter diferentes capacidades.

Tem LLM que é focado em gerar texto, outros em gerar código, outros em gerar imagens, outros em gerar vídeos. E assim por diante.

Então, dependendo do problema que você quer resolver com seu Agente, você vai escolher o LLM que mais se adapta a esse problema.

## Que tarefas são essas?

Aqui não dá para colocar um limite certo. Na teoria, os Agentes podem realizar uma ampla variedade de tarefas, dependendo de sua programação e dos dados disponíveis.

Sendo um pouco mais prático, podemos colocar um Agente para tomar determinadas ações com base em uma resposta de um LLM.
Imagine o seguinte cenário: você identifica o usuário que está logado no seu sistema e, com base nas informações desse usuário, pode usar uma __Function Calling__ e pedir para um Modelo de IA analisar os dados desse usuário e tomar uma ação. Essa ação pode ser qualquer coisa: desde enviar um e-mail, disparar uma notificação, recomendar algo para o usuário, entre outros.

Explicando melhor sobre Function Calling/JSON Calling: a ideia é que você fazer uma chamada para o Modelo de IA, de uma volta estruturada e passando os dados necessários como parâmetros. O Modelo de IA irá processar esses dados e retornar uma resposta estruturada, que pode ser utilizada pelo Agente para tomar uma ação. A chave está na resposta "estruturada" do modelo. No nosso exemplo, o modelo da IA pode retornar algo como:
```json
{
  "action": "send_email",
  "recipient": "user@example.com",
  "subject": "Novidades do Sistema",
  "body": "Olá, que bom que está de volta ao nosso sistema! Aqui estão algumas novidades que podem te interessar."
}

```

O Agente pode então interpretar essa resposta e executar a ação correspondente. Isso obviamente precisa ser programado.
Nesse exemplo, primeiro vamos usar a IA para nos dizer o que fazer; em seguida, vamos programar o Agente para buscar as novidades do sistema e enviar o e-mail.
Mas talvez o modelo de IA retorne algo diferente, como:
```json
{
  "action": "recommend_product",
  "product_id": "12345"
}
```

Nesse caso, o Agente não vai enviar um e-mail, mas sim recomendar um produto.
Claro, tudo isso depende dos prompts e das informações que você passar para o modelo de IA no tal __Function Calling__.
Não vou me aprofundar em Function Calling agora, mas, na OpenAI, por exemplo, eles definem um "protocolo" para você especificar as funções que o modelo pode chamar. Você pode definir os parâmetros, os tipos de dados, etc.

No nosso exemplo, passamos pelos passos 1, 2 e 3 do ciclo de vida do Agente. O Agente percebeu o ambiente (o usuário logado), tomou uma decisão (o que fazer com esse usuário) e executou a ação (enviar um e-mail ou recomendar um produto). 


## Quais ambientes?

Aqui você tem várias opções, mas vai depender muito do seu cenário, principalmente de como as informações vão ser coletadas.
Há ferramentas de mercado como: n8n, Zapier, Make, entre outros. São ferramentas que permitem criar esse fluxo de um Agente que exemplifiquei acima. A grande vantagem dessas ferramentas é facilitar a integração com serviços externos, como serviços da Google, Microsoft, entre outros, que geralmente possuem uma burocracia para integrar manualmente.

A desvantagem é a limitação de algumas ações e a entrada de dados pode ser limitada. Diferente se você programar um Agente usando o framework __LangChain__, por exemplo.

No momento em que estou escrevendo este artigo, o LangChain é o framework mais utilizado para criar Agentes de IA. Ele é uma biblioteca Python que não só permite criar Agentes, mas também integra com LLMs, APIs, bancos de dados, entre outros. Com ele você não tem nenhuma limitação, mas tem o custo do desenvolvimento.

O __LangChain__ está liberando uma biblioteca para JavaScript, mas ainda não está tão madura quanto a versão Python.


## Aprendizado 

O aprendizado, que corresponde aos passos 4 e 5 do ciclo de vida do Agente, é um pouco mais complexo. Mas, seguindo no exemplo, podemos identificar que o Modelo de IA sempre responde o mesmo tipo de ação para o mesmo usuário, por exemplo.
Logo, o Agente vai "aprender" com isso e, na próxima vez, não vai precisar perguntar para o modelo de IA o que fazer; ele pode simplesmente pular essa etapa e executar a ação diretamente. Isso ganha tempo e melhora a performance do Agente.
Eventualmente, o Agente pode até não pular a etapa e verificar o que o modelo de IA retornaria, para ver se continua o mesmo padrão ou não.

## O Mínimo

Isso que expliquei é o mínimo que você precisa saber para entender o conceito de Agente de IA. Como você pode ver, o conceito é simples, mas a implementação pode ter suas complexidades.


## Referências:

- [O que é um Agente de IA?](https://cloud.google.com/discover/what-are-ai-agents)
- [n8n Blog: AI Agents](https://blog.n8n.io/ai-agents/)
- [What Is Agentic AI, and How Will It Change Work?](https://hbr.org/2024/12/what-is-agentic-ai-and-how-will-it-change-work)
- [What are AI agents?](https://www.ibm.com/think/topics/ai-agents)
- [AI Agents 2025: Expectations vs. Reality](https://www.ibm.com/think/insights/ai-agents-2025-expectations-vs-reality)
- [How AI Agents Will Revolutionize Your Day-to-Day Life](https://www.forbes.com/sites/bernardmarr/2025/03/25/how-ai-agents-will-revolutionize-your-day-to-day-life/)
- [OpenAI Function Calling Documentação](https://platform.openai.com/docs/guides/function-calling?api-mode=)
- [LangChain Documentação](https://www.langchain.com/docs/get_started/getting_started)
- [AI Agents, Clearly Explained](https://www.youtube.com/watch?v=FwOTs4UxQS4)


+++start+++

## Anterior
[IA: Diferença entre LLM, UNET e RAG. (Parte 1)](1.ia-diferenca-llm-unet-rag)


+++end+++